This is a list of useful links for the reader. They mostly point to software referenced in this workbook.

AntConc (http://www.laurenceanthony.net/software/antconc/) - “A freeware corpus analysis toolkit for concordancing and text analysis.”

Apache OpenNLP (http://opennlp.apache.org/index.html) - “OpenNLP supports the most common NLP tasks, such as tokenization, sentence segmentation, part-of-speech tagging, named entity extraction, chunking, parsing, language detection and coreference resolution.”

Basic Text Analysis with Command Line Tools in Linux (https://williamjturkel.net/2013/06/15/basic-text-analysis-with-command-line-tools-in-linux/) - A useful webpage outlining how to do bits of text mining from the Unix/Linux command line.

BBEdit (https://www.barebones.com/products/bbedit/) - “BBEdit is the leading professional HTML and text editor for macOS. This award-winning product has been crafted to serve the needs of writers, Web authors and software developers, and provides an abundance of features for editing, searching, and manipulation of text. An intelligent interface provides easy access to BBEdit’s best-of-class features, including grep pattern matching, search and replace across multiple files, project definition tools, function navigation and syntax coloring for numerous source code languages, code folding, FTP and SFTP open and save, AppleScript, macOS Unix scripting support, text and code completion, and of course a complete set of robust HTML markup tools.”

CLAWS part-of-speech tagger (http://ucrel.lancs.ac.uk/claws/) - “Part-of-speech (POS) tagging, also called grammatical tagging, is the commonest form of corpus annotation, and was the first form of annotation to be developed by UCREL at Lancaster. Our POS tagging software for English text, CLAWS (the Constituent Likelihood Automatic Word-tagging System), has been continuously developed since the early 1980s. The latest version of the tagger, CLAWS4, was used to POS tag c.100 million words of the British National Corpus (BNC).”

curl (https://curl.haxx.se/) - “curl is used in command lines or scripts to transfer data. It is also used in cars, television sets, routers, printers, audio equipment, mobile phones, tablets, settop boxes, media players and is the internet transfer backbone for thousands of software applications affecting billions of humans daily.”

DiRT Directory (http://dirtdirectory.org/) - “Bamboo DiRT is a tool, service, and collection registry of digital research tools for scholarly use... and makes it easy for digital humanists and others conducting digital research to find and compare resources ranging from content management systems to music OCR, statistical analysis packages to mindmapping software.”

Finding and Preparing Text (http://hermeneuti.ca/finding-preparing-text) - “How do you find an electronic text of a work you want to study? How should you prepare it for study with a tool like Voyant? This appendix provides a short guide to finding and preparing an electronic text.”

Internet Archive API (http://blog.archive.org/developers/) - “[The] Internet Archive encourages developers to [programatically] add media to archive.org as well as to consume and repurpose metadata and media.”

Log-linear Part-Of-Speech Tagger (https://nlp.stanford.edu/software/tagger.shtml) - “A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc., although generally computational applications use more fine-grained POS tags like “noun-plural”. This software is a Java implementation of the log-linear part-of-speech taggers described in [a number of papers]...”

MALLET (http://mallet.cs.umass.edu/) - “MALLET is a Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text.”

Named Entity Recognizer (https://nlp.stanford.edu/software/CRF-NER.shtml) - “Stanford NER is a Java implementation of a Named Entity Recognizer. Named Entity Recognition (NER) labels sequences of words in a text which are the names of things, such as person and company names, or gene and protein names. It comes with well-engineered feature extractors for Named Entity Recognition, and many options for defining feature extractors. Included with the download are good named entity recognizers for English, particularly for the 3 classes (PERSON, ORGANIZATION, LOCATION), and we also make available on this page various other models for different languages and circumstances, including models trained on just the CoNLL 2003 English training data.”

Natural Language Toolkit (http://www.nltk.org/) - “NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.”

Notepad++ (https://notepad-plus-plus.org/) - “Notepad++ is a free (as in ‘free speech’ and also as in ‘free beer’) source code editor and Notepad replacement that supports several languages. Running in the MS Windows environment, its use is governed by GPL License.””

OpenRefine (http://openrefine.org/) - “OpenRefine (formerly Google Refine) is a powerful tool for working with messy data: cleaning it; transforming it from one format into another; and extending it with web services and external data.”

Tableau Public (https://public.tableau.com/s/) - “From connection through collaboration, Tableau is the most powerful, secure, and flexible end-to-end analytics platform for your data. Match the skills of any data worker with the capabilities they need. Prepare, create, explore, or view trusted data with subscriptions to Tableau’s governed self-service analytics platform. Upgrade to Tableau Creator, a new subscription offering that gives you Tableau Desktop, Tableau Prep, and a server seat.”

Tika (http://tika.apache.org/) - “The Apache Tika™ toolkit detects and extracts metadata and text from over a thousand different file types (such as PPT, XLS, and PDF). All of these file types can be parsed through a single interface, making Tika useful for search engine indexing, content analysis, translation, and much more.”

topic-modeling-tool (https://github.com/senderle/topic-modeling-tool) - “A point-and-click tool for creating and analyzing topic models produced by MALLET.”

Unix for Poets (https://www.cs.upc.edu/~padro/Unixforpoets.pdf) - A gentle introduction to counting & tabulating from the command line.

Voyant Tools (http://voyant-tools.org/) - “Voyant Tools is a web-based reading and analysis environment for digital texts.”

Wget (https://www.gnu.org/software/wget/) - “GNU Wget is a free software package for retrieving files using HTTP, HTTPS, FTP and FTPS the most widely-used Internet protocols. It is a non-interactive commandline tool, so it may easily be called from scripts, cron jobs, terminals without X-Windows support, etc.”

